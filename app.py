import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
import torch.nn.functional as F
from PIL import Image

# --- 1. C·∫§U H√åNH GIAO DI·ªÜN ---
st.set_page_config(page_title="Ch·∫©n ƒëo√°n Ung th∆∞ da", page_icon="ü©∫")
st.title("ü©∫ H·ªá th·ªëng Ch·∫©n ƒëo√°n Ung th∆∞ Da (Ensemble AI)")
st.write("T·∫£i l√™n h√¨nh ·∫£nh v·∫øt th∆∞∆°ng da ƒë·ªÉ h·ªá th·ªëng ph√¢n t√≠ch.")

# --- 2. LOAD MODEL (S·ª≠ d·ª•ng Cache ƒë·ªÉ kh√¥ng ph·∫£i load l·∫°i m·ªói l·∫ßn) ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

@st.cache_resource
def load_ensemble_models():
    # Khai b√°o h√†m load model (Code ƒë√£ s·ª≠a chu·∫©n c·ªßa b·∫°n)
    def load_single_model(arch_type, path):
        model = None
        try:
            checkpoint = torch.load(path, map_location=torch.device('cpu'))
            state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint
            
            if arch_type == 'resnet50':
                model = models.resnet50(weights=None)
                model.fc = nn.Sequential(nn.Dropout(0.6), nn.Linear(model.fc.in_features, 7))
            elif arch_type == 'densenet121':
                model = models.densenet121(weights=None)
                if 'classifier.weight' in state_dict:
                     model.classifier = nn.Linear(model.classifier.in_features, 7)
                else:
                     model.classifier = nn.Sequential(nn.Dropout(0.5), nn.Linear(model.classifier.in_features, 7))
            elif arch_type == 'efficientnet_b4':
                model = models.efficientnet_b4(weights=None)
                model.classifier[1] = nn.Linear(model.classifier[1].in_features, 7)
            
            model.load_state_dict(state_dict, strict=False)
            model.to(device)
            model.eval()
            return model
        except Exception as e:
            st.error(f"L·ªói load {arch_type}: {e}")
            return None

    # ƒê·ªîI ƒê∆Ø·ªúNG D·∫™N T·ªöI FILE TR√äN M√ÅY B·∫†N
    m_res = load_single_model('resnet50', 'skin_resnet50.pth')
    m_dense = load_single_model('densenet121', 'best_densenet121.pth') # File DenseNet m·ªõi train l·∫°i
    m_eff = load_single_model('efficientnet_b4', 'best_efficientnet_b4.pth')
    
    return m_res, m_dense, m_eff

# Load model ngay khi v√†o app
with st.spinner('ƒêang kh·ªüi ƒë·ªông "Tam gi√°c v√†ng" AI... Vui l√≤ng ƒë·ª£i!'):
    model_resnet, model_dense, model_eff = load_ensemble_models()

if model_resnet and model_dense and model_eff:
    st.success("‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")

# --- 3. X·ª¨ L√ù ·∫¢NH ---
labels_map = {
    0: 'AKIEC (D√†y s·ª´ng quang h√≥a)',
    1: 'BCC (Ung th∆∞ bi·ªÉu m√¥ t·∫ø b√†o ƒë√°y)',
    2: 'BKL (T·ªïn th∆∞∆°ng l√†nh t√≠nh)',
    3: 'DF (U x∆° da)',
    4: 'MEL (Ung th∆∞ h·∫Øc t·ªë - Nguy hi·ªÉm)',
    5: 'NV (N·ªët ru·ªìi l√†nh t√≠nh)',
    6: 'VASC (T·ªïn th∆∞∆°ng m·∫°ch m√°u)'
}

def process_image(image):
    # Transform cho EfficientNet (380)
    transform_eff = transforms.Compose([
        transforms.Resize((400, 400)),
        transforms.CenterCrop(380),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    img_tensor = transform_eff(image).unsqueeze(0).to(device)
    return img_tensor

# --- 4. GIAO DI·ªÜN CH√çNH ---
uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh...", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    # Hi·ªÉn th·ªã ·∫£nh
    image = Image.open(uploaded_file).convert('RGB')
    st.image(image, caption='·∫¢nh ƒë√£ t·∫£i l√™n', use_column_width=True)
    
    if st.button('üîç Ph√¢n t√≠ch ngay'):
        with st.spinner('ƒêang h·ªôi ch·∫©n 3 chuy√™n gia AI...'):
            img_tensor = process_image(image)
            
            # 1. EfficientNet (Ch·∫°y ·∫£nh g·ªëc 380)
            out_eff = model_eff(img_tensor)
            prob_eff = F.softmax(out_eff, dim=1)

            # 2. ResNet & DenseNet (Resize xu·ªëng 224)
            img_small = F.interpolate(img_tensor, size=(224, 224), mode='bilinear')
            
            out_res = model_resnet(img_small)
            prob_res = F.softmax(out_res, dim=1)
            
            out_dense = model_dense(img_small)
            prob_dense = F.softmax(out_dense, dim=1)

            # 3. Ensemble (Weighted Average)
            # Tr·ªçng s·ªë b·∫°n c√≥ th·ªÉ t√πy ch·ªânh
            final_prob = (prob_res * 0.4) + (prob_dense * 0.3) + (prob_eff * 0.3)
            
            # L·∫•y k·∫øt qu·∫£
            top_p, top_class = torch.max(final_prob, 1)
            pred_idx = top_class.item()
            confidence = top_p.item() * 100

        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        st.markdown("---")
        if pred_idx in [1, 4]: # C√°c l·ªõp Ung th∆∞ nguy hi·ªÉm
            st.error(f"### ‚ö† K·∫æT QU·∫¢: {labels_map[pred_idx]}")
        elif pred_idx in [2, 5]: # L√†nh t√≠nh
            st.success(f"### üéâ K·∫æT QU·∫¢: {labels_map[pred_idx]}")
        else:
            st.warning(f"### ‚Ñπ K·∫æT QU·∫¢: {labels_map[pred_idx]}")
            
        st.info(f"ƒê·ªô tin c·∫≠y: **{confidence:.2f}%**")
        
        # Show chi ti·∫øt x√°c su·∫•t
        st.write("Chi ti·∫øt x√°c su·∫•t c√°c l·ªõp:")
        probs = final_prob.detach().cpu().numpy()[0]
        st.bar_chart({labels_map[i]: probs[i] for i in range(7)})