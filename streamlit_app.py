import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
import torch.nn.functional as F
from PIL import Image
import gc # <--- Má»šI: ThÆ° viá»‡n dá»n rÃ¡c bá»™ nhá»›

# --- Cáº¤U HÃŒNH ---
st.set_page_config(page_title="Cháº©n Ä‘oÃ¡n Ung thÆ° da", page_icon="ðŸ©º")
st.title("ðŸ©º Há»‡ thá»‘ng Cháº©n Ä‘oÃ¡n Ung thÆ° Da")

# Ã‰p cháº¡y CPU Ä‘á»ƒ trÃ¡nh lá»—i CUDA trÃªn Cloud vÃ  tiáº¿t kiá»‡m VRAM áº£o
device = torch.device('cpu') 

@st.cache_resource # <--- QUAN TRá»ŒNG: Giá»¯ model trong cache Ä‘á»ƒ khÃ´ng load láº¡i
def load_ensemble_models():
    def load_single_model(arch_type, path):
        model = None
        try:
            # map_location=device lÃ  CPU
            checkpoint = torch.load(path, map_location=device)
            state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint
            
            if arch_type == 'resnet50':
                model = models.resnet50(weights=None)
                model.fc = nn.Sequential(nn.Dropout(0.6), nn.Linear(model.fc.in_features, 7))
            elif arch_type == 'densenet121':
                model = models.densenet121(weights=None)
                if 'classifier.weight' in state_dict:
                     model.classifier = nn.Linear(model.classifier.in_features, 7)
                else:
                     model.classifier = nn.Sequential(nn.Dropout(0.5), nn.Linear(model.classifier.in_features, 7))
            elif arch_type == 'efficientnet_b4':
                model = models.efficientnet_b4(weights=None)
                model.classifier[1] = nn.Linear(model.classifier[1].in_features, 7)
            
            model.load_state_dict(state_dict, strict=False)
            model.to(device)
            model.eval()
            return model
        except Exception as e:
            return None

    # Load 3 model
    m_res = load_single_model('resnet50', 'skin_resnet50.pth')
    m_dense = load_single_model('densenet121', 'best_densenet121.pth')
    m_eff = load_single_model('efficientnet_b4', 'best_efficientnet_b4.pth')
    
    return m_res, m_dense, m_eff

# Load models
with st.spinner('Äang khá»Ÿi Ä‘á»™ng AI...'):
    model_resnet, model_dense, model_eff = load_ensemble_models()

if model_resnet and model_dense and model_eff:
    st.success("âœ… Há»‡ thá»‘ng sáºµn sÃ ng!")

# --- Xá»¬ LÃ áº¢NH ---
labels_map = { 0: 'AKIEC (DÃ y sá»«ng quang hÃ³a)', 1: 'BCC (Ung thÆ° biá»ƒu mÃ´ táº¿ bÃ o Ä‘Ã¡y)', 2: 'BKL (Tá»•n thÆ°Æ¡ng lÃ nh tÃ­nh)', 3: 'DF (U xÆ¡ da)', 4: 'MEL (Ung thÆ° háº¯c tá»‘ - Nguy hiá»ƒm)', 5: 'NV (Ná»‘t ruá»“i lÃ nh tÃ­nh)', 6: 'VASC (Tá»•n thÆ°Æ¡ng máº¡ch mÃ¡u)' }

uploaded_file = st.file_uploader("Chá»n áº£nh...", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert('RGB')
    # Sá»¬A Lá»–I WARNING: DÃ¹ng use_container_width thay vÃ¬ use_column_width
    st.image(image, caption='áº¢nh táº£i lÃªn', use_container_width=True) 
    
    if st.button('ðŸ” PhÃ¢n tÃ­ch'):
        with st.spinner('Äang xá»­ lÃ½...'):
            # Transform
            transform = transforms.Compose([
                transforms.Resize((224, 224)), # DÃ¹ng áº£nh nhá» 224 cho táº¥t cáº£ Ä‘á»ƒ tiáº¿t kiá»‡m RAM (cháº¥p nháº­n giáº£m nháº¹ Ä‘á»™ chÃ­nh xÃ¡c EfficientNet)
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
            
            img_tensor = transform(image).unsqueeze(0).to(device)
            
            # Inference (DÃ¹ng with torch.no_grad Ä‘á»ƒ khÃ´ng tá»‘n RAM lÆ°u gradient)
            with torch.no_grad():
                out_res = model_resnet(img_tensor)
                prob_res = F.softmax(out_res, dim=1)
                
                out_dense = model_dense(img_tensor)
                prob_dense = F.softmax(out_dense, dim=1)

                # Resize lÃªn 380 cho EfficientNet (náº¿u RAM chá»‹u ná»•i)
                # Hoáº·c dÃ¹ng luÃ´n áº£nh 224 cho EfficientNet Ä‘á»ƒ trÃ¡nh crash (cháº¥p nháº­n hy sinh chÃºt Ä‘á»™ chÃ­nh xÃ¡c)
                img_380 = F.interpolate(img_tensor, size=(380, 380), mode='bilinear')
                out_eff = model_eff(img_380)
                prob_eff = F.softmax(out_eff, dim=1)

                final_prob = (prob_res * 0.4) + (prob_dense * 0.3) + (prob_eff * 0.3)
                top_p, top_class = torch.max(final_prob, 1)
                
                # --- Dá»ŒN RÃC NGAY Láº¬P Tá»¨C ---
                del img_tensor, img_380, out_res, out_dense, out_eff
                gc.collect()

            pred_idx = top_class.item()
            confidence = top_p.item() * 100

        st.info(f"Káº¿t quáº£: **{labels_map[pred_idx]}** ({confidence:.2f}%)")
        st.bar_chart(final_prob.detach().numpy()[0])