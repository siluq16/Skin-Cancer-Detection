import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
import torch.nn.functional as F
from PIL import Image
import gc
import os

# --- 1. C·∫§U H√åNH ---
st.set_page_config(page_title="Ch·∫©n ƒëo√°n Ung th∆∞ da", page_icon="ü©∫")
st.title("ü©∫ H·ªá th·ªëng Ch·∫©n ƒëo√°n Ung th∆∞ Da")
st.caption("üöÄ Phi√™n b·∫£n High-Res (380px) - Ch·∫ø ƒë·ªô ti·∫øt ki·ªám RAM")

device = torch.device('cpu')

# --- 2. H√ÄM LOAD & PREDICT TU·∫¶N T·ª∞ (QUAN TR·ªåNG) ---
# Kh√¥ng d√πng @st.cache_resource cho model n·ªØa v√¨ ta c·∫ßn x√≥a n√≥ ngay sau khi d√πng
def predict_one_model(arch_type, path, img_tensor):
    model = None
    prob = None
    try:
        # Load Model
        checkpoint = torch.load(path, map_location='cpu')
        state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint
        
        if arch_type == 'resnet50':
            model = models.resnet50(weights=None)
            model.fc = nn.Sequential(nn.Dropout(0.6), nn.Linear(model.fc.in_features, 7))
        elif arch_type == 'densenet121':
            model = models.densenet121(weights=None)
            if 'classifier.weight' in state_dict:
                 model.classifier = nn.Linear(model.classifier.in_features, 7)
            else:
                 model.classifier = nn.Sequential(nn.Dropout(0.6), nn.Linear(model.classifier.in_features, 7))
        elif arch_type == 'efficientnet_b4':
            model = models.efficientnet_b4(weights=None)
            model.classifier[1] = nn.Linear(model.classifier[1].in_features, 7)
        
        model.load_state_dict(state_dict, strict=False)
        model.to(device)
        model.eval()
        
        # D·ª± ƒëo√°n
        with torch.no_grad():
            out = model(img_tensor)
            prob = F.softmax(out, dim=1)
            
    except Exception as e:
        st.error(f"L·ªói khi ch·∫°y {arch_type}: {e}")
        return None
    finally:
        # --- D·ªåN R√ÅC C·ª∞C M·∫†NH ---
        del model
        del checkpoint
        if 'state_dict' in locals(): del state_dict
        torch.cuda.empty_cache() # D√π ch·∫°y CPU v·∫´n g·ªçi cho ch·∫Øc
        gc.collect() # √âp d·ªçn RAM ngay l·∫≠p t·ª©c
        
    return prob

# --- 3. X·ª¨ L√ù ·∫¢NH ---
labels_map = {
    0: 'AKIEC (D√†y s·ª´ng quang h√≥a)',
    1: 'BCC (Ung th∆∞ bi·ªÉu m√¥ t·∫ø b√†o ƒë√°y)',
    2: 'BKL (T·ªïn th∆∞∆°ng l√†nh t√≠nh)',
    3: 'DF (U x∆° da)',
    4: 'MEL (Ung th∆∞ h·∫Øc t·ªë - Nguy hi·ªÉm)',
    5: 'NV (N·ªët ru·ªìi l√†nh t√≠nh)',
    6: 'VASC (T·ªïn th∆∞∆°ng m·∫°ch m√°u)'
}


uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh...", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert('RGB')
    st.image(image, caption='·∫¢nh ƒë√£ t·∫£i l√™n', use_container_width=True)

    if st.button('üîç Ph√¢n t√≠ch chi ti·∫øt (380px)'):
        progress_bar = st.progress(0, text="ƒêang kh·ªüi t·∫°o...")
        
        try:
            final_prob = torch.zeros(1, 7).to(device)
            models_ran = 0
            
            # --- GIAI ƒêO·∫†N 1: RESNET50 ---
            progress_bar.progress(10, text="ƒêang ch·∫°y ResNet50 (1/3)...")
            # ResNet th∆∞·ªùng train ·ªü 224, d√πng 380 c≈©ng ƒë∆∞·ª£c nh∆∞ng t·ªën RAM, ta resize v·ªÅ 224 cho n√≥ nh·∫π b·ªõt
            # ƒë·ªÉ d√†nh RAM cho EfficientNet sau c√πng.
            t_res = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
            img_res = t_res(image).unsqueeze(0).to(device)
            
            prob_res = predict_one_model('resnet50', 'skin_resnet50.pth', img_res)
            if prob_res is not None:
                final_prob += prob_res * 0.4
                models_ran += 1
            del img_res, prob_res
            gc.collect()

            # --- GIAI ƒêO·∫†N 2: DENSENET121 ---
            progress_bar.progress(40, text="ƒêang ch·∫°y DenseNet121 (2/3)...")
            # DenseNet c≈©ng ch·∫°y 224
            img_dense = t_res(image).unsqueeze(0).to(device) # T√°i s·ª≠ d·ª•ng transform 224
            
            prob_dense = predict_one_model('densenet121', 'best_densenet121.pth', img_dense)
            if prob_dense is not None:
                final_prob += prob_dense * 0.3
                models_ran += 1
            del img_dense, prob_dense
            gc.collect()

            # --- GIAI ƒêO·∫†N 3: EFFICIENTNET-B4 (BOSS CU·ªêI - 380PX) ---
            progress_bar.progress(70, text="ƒêang ch·∫°y EfficientNet-B4 (3/3) - High Res...")
            # ƒê√¢y l√† l√∫c d√πng 380px nh∆∞ b·∫°n mu·ªën
            t_eff = transforms.Compose([
                transforms.Resize((400, 400)), # Resize to h∆°n ch√∫t
                transforms.CenterCrop(380),    # Crop ƒë√∫ng chu·∫©n 380
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
            img_eff = t_eff(image).unsqueeze(0).to(device)
            
            prob_eff = predict_one_model('efficientnet_b4', 'best_efficientnet_b4.pth', img_eff)
            if prob_eff is not None:
                final_prob += prob_eff * 0.3
                models_ran += 1
            del img_eff, prob_eff
            gc.collect()

            progress_bar.progress(100, text="Ho√†n t·∫•t!")

            if models_ran == 0:
                st.error("‚ùå L·ªói: Kh√¥ng ch·∫°y ƒë∆∞·ª£c model n√†o!")
                st.stop()

            # L·∫•y k·∫øt qu·∫£
            top_p, top_class = torch.max(final_prob, 1)
            pred_idx = top_class.item()
            confidence = top_p.item() * 100

            # Hi·ªÉn th·ªã
            st.divider()
            if pred_idx in [1, 4]:
                st.error(f"### ‚ö† K·∫æT QU·∫¢: {labels_map[pred_idx]}")
            elif pred_idx in [2, 5]:
                st.success(f"### üéâ K·∫æT QU·∫¢: {labels_map[pred_idx]}")
            else:
                st.warning(f"### ‚Ñπ K·∫æT QU·∫¢: {labels_map[pred_idx]}")
                
            st.info(f"ƒê·ªô tin c·∫≠y: **{confidence:.2f}%**")
            st.bar_chart(final_prob.detach().numpy()[0])
            
        except Exception as e:
            st.error(f"C√≥ l·ªói x·∫£y ra: {e}")